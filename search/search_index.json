{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#picket-unsupervised-particle-picking-protocol-for-cryo-electron-tomograms","title":"PickET: Unsupervised particle picking protocol for cryo-electron tomograms","text":"<p>Python package to pick particles in cryo-electron tomograms in an unsupervised manner</p> <p></p>"},{"location":"#table-of-contents","title":"Table of contents","text":"<ol> <li>Getting started </li> <li>Usage instructions <ul> <li>Input for S1</li> <li>How to run S1?</li> <li>Obtaining particle cluster ID </li> <li>Input for S2</li> <li>How to run S2?</li> </ul> </li> <li> <p>Understanding the outputs</p> </li> <li> <p>Scripts for reproducing figures for the paper: evaluations. </p> </li> <li>Helper scripts for preprocessing the ground truth annotations: preprocessing ground truth. </li> <li>Other useful helper scripts are provided: accessories. </li> </ol>"},{"location":"#publication-and-data","title":"Publication and Data","text":"<ul> <li>Arvindekar, S., Golatkar, O., &amp; Viswanath, S. (2025). PickET: An unsupervised method for localizing macromolecules in cryo-electron tomograms. bioRxiv. https://doi.org/10.1101/2025.08.20.671250</li> <li>Data is deposited in Zenodo </li> </ul>"},{"location":"#information","title":"Information","text":"<p>Author(s): Shreyas Arvindekar, Shruthi Viswanath Date: June 1st, 2025 License: CC BY-SA 4.0 This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. Testable: Yes Publications:  Arvindekar, S., Golatkar, O., &amp; Viswanath, S. (2025). PickET: An unsupervised method for localizing macromolecules in cryo-electron tomograms. bioRxiv. https://doi.org/10.1101/2025.08.20.671250</p>"},{"location":"evaluations/","title":"Evaluating predictions from PickET","text":""},{"location":"evaluations/#centroid-based-evaluation","title":"Centroid-based evaluation","text":"<p>This evaluation computes the precision, recall and F1-score for the predicted centroids by comparing the shortest Euclidean distance between predicted centroids and ground truth centroids.</p> <p>Along with these computations, N (where, N is number of predictions from PickET) number of random predictions are also made to get the random baseline. </p> <p>These computations are made using the centroid assessment script which can be run as follows: <pre><code>python evaluations/centroid_assessment.py assessment_params.yaml\n</code></pre></p> <p>where <code>assessment_params.yaml</code> is a configurations file for the assessment. A detailed description of this file can be found in the example.</p>"},{"location":"evaluations/#compare-all-the-workflows","title":"Compare all the workflows","text":"<p>All the workflows can be compared after computing the centroid based evaluation by running the comparison script as follows: <pre><code>python plotting/compare_workflows.py &lt;metric&gt; &lt;dataset_id&gt; &lt;output_dir&gt; &lt;path_to_centroid-based_evaluation_output/*.yaml&gt;\n</code></pre></p> <p>where <code>metric</code> can be <code>Precision</code>,<code>Recall</code>, <code>F1-score</code>, etc. Essentially, it can be any of the keys from the evaluation output files.</p>"},{"location":"evaluations/#compute-particle-wise-recall","title":"Compute particle-wise recall","text":"<p>We also checked which particles were most likely to get picked in order to then understand the characteristics of a particle that made it more likely to be picked by PickET. This was done by running the particle-wise recall script as follows: <pre><code>python evaluations/particle_wise_recall.py assessment_params.yaml &lt;output_dir&gt;\n</code></pre></p> <p>This script generates several <code>.yaml</code> files, each of which contain the average recall across all tomograms for each particle type as specified in the ground truth file for the workflow specified in the name of the file. This file can be better visualized as a scatter plot which can be generated by the following scripts: 1. For TomoTwin tomograms 2. For CZI tomograms</p> <p>These scripts can be run as follows: 1. For TomoTwin tomograms: <pre><code>python plotting/plot_particlewise_recall_tomotwin.py &lt;particle-wise_recall_fpath&gt; &lt;particle_details_fname&gt;\n</code></pre></p> <p>The particle_details_fname contains the details of each particle type in the dataset such as the molecular weight, radius of gyration, etc.</p> <ol> <li>for CZI tomograms: <pre><code>python plotting/plot_particlewise_recall_czi.py &lt;particle-wise_recall_fpath&gt; &lt;dataset_name&gt;\n</code></pre></li> </ol>"},{"location":"evaluations/#comparison-with-milopyp","title":"Comparison with MiLoPYP","text":"<p>The details about the installation and running MiLoPYP are mentioned in the How I ran MiLoPYP document.</p>"},{"location":"evaluations/#1-convert-the-predictions-to-a-yaml-format","title":"1. Convert the predictions to a <code>.yaml</code> format","text":"<p>The predictions obtained after running the first (Cellular content exploration) step were converted to a format similar to the particle centroids predicted by PickET (See also PickET outputs) using the conversion script. This script was run as follows: <pre><code>python accessories/convert_milopyp_preds_to_yaml.py &lt;output_from_MiLoPYP&gt; &lt;input_text_file_to_MiLoPYP&gt; &lt;output_dir&gt;\n</code></pre></p> <p>where <code>&lt;output_from_MiLoPYP&gt;</code> is the <code>all_output_info.npz</code> generated by the inference step of the cellular content exploration module of MiLoPYP; <code>&lt;input_text_file_to_MiLoPYP&gt;</code> is the <code>.txt</code> provided as input to MiLoPYP; and <code>&lt;output_dir&gt;</code> is the path to the directory where the output <code>.yaml</code> files should be saved/</p>"},{"location":"evaluations/#2-compare-the-predictions-from-milopyp-and-picket","title":"2. Compare the predictions from MiLoPYP and PickET","text":"<p>The precision, recall and F1-score on the MiLoPYP predictions can now be computed in the same way as that for PickET predictions (See evaluating PickET predictions).  </p> <p>The comparison can then be plotted by running the plotting script as follows: <pre><code>python evaluations/comparison_w_milopyp.py &lt;path_to_MiLoPYP_evaluation&gt; &lt;path_to_PickET_evaluation&gt;\n</code></pre></p> <p>where <code>&lt;path_to_MiLoPYP_evaluation&gt;</code> is the output <code>.yaml</code> file generated from running the evaluation step above on MiLoPYP predictions; similarly, the <code>&lt;path_to_PickET_evaluation&gt;</code> is the output <code>.yaml</code> file generated from running the evaluation step above on PickET predictions.</p>"},{"location":"evaluations/#plot-particle-wise-segmentations-fig-6-in-the-paper","title":"Plot particle-wise segmentations (Fig. 6 in the paper)","text":"<p>Run the following commands, one at a time, for each each of the rows in the figure: <pre><code>python plotting/make_a_particle_wise_segmentation_image.py /data2/shreyas/mining_tomograms/working/s1_clean_results_picket_v4/czi_ds-10001_denoised/instance_segmentations/instance_segmentation_0_gabor_kmeans_watershed_segmentation.h5 450 550 ./\n\npython plotting/make_a_particle_wise_segmentation_image.py /data2/shreyas/mining_tomograms/working/s1_clean_results_picket_v4/czi_ds-10301_denoised/instance_segmentations/instance_segmentation_0_gabor_kmeans_watershed_segmentation.h5 225 275 ./\n\npython plotting/make_a_particle_wise_segmentation_image.py /data2/shreyas/mining_tomograms/working/s1_clean_results_picket_v4/czi_ds-10301_denoised/instance_segmentations/instance_segmentation_1_gabor_kmeans_watershed_segmentation.h5 225 275 ./\n\npython plotting/make_a_particle_wise_segmentation_image.py /data2/shreyas/mining_tomograms/working/s1_clean_results_picket_v4/czi_ds-10301_denoised/instance_segmentations/instance_segmentation_3_gabor_kmeans_watershed_segmentation.h5 225 275 ./\n\npython plotting/make_a_particle_wise_segmentation_image.py /data2/shreyas/mining_tomograms/working/s1_clean_results_picket_v4/czi_ds-10301_denoised/instance_segmentations/instance_segmentation_4_gabor_kmeans_watershed_segmentation.h5 225 275 ./\n</code></pre></p> <p>Each of these commands will load a Napari window with the input tomogram, semantic segmentation, instance segmentation and a particle-wise segmentation for the input tomogram. Save a screenshot of the tomogram alone, tomogram overlayed with instance segmentation and instance segmentation alone on the Z-slice that gets opened by default. Once you close the Napari window, a set of <code>.mrc</code> files will be saved, each of which contains a binary matrix of the shape of the input tomogram. Each of these <code>.mrc</code> files is a segmentation for each particle type. Load these in ChimeraX, set the thresholds to <code>0.999</code> and color them as per the key provided in the script. Set the step size to <code>1</code>, graphics to <code>soft</code> mode and save the image using the <code>save</code> command. </p>"},{"location":"how_we_ran_milopyp/","title":"How we ran MiLoPYP (Pattern Mining (Mi) and particle Localization (Lo) PYthon (PY) Pipeline (P))","text":"<p>This documentation takes content from the official MiLoPYP tutorial </p>"},{"location":"how_we_ran_milopyp/#installation","title":"Installation","text":""},{"location":"how_we_ran_milopyp/#1-create-a-new-conda-environment-optional-but-recommended","title":"1. Create a new conda environment [optional, but recommended]","text":"<pre><code>conda create --name MiLoPYP python=3.8\n</code></pre> <p>And activate the environment. <pre><code>conda activate MiLoPYP\n</code></pre></p>"},{"location":"how_we_ran_milopyp/#2-clone-the-cet_pick-repo","title":"2. Clone the cet_pick repo","text":"<pre><code>git clone https://github.com/nextpyp/cet_pick.git\n</code></pre>"},{"location":"how_we_ran_milopyp/#3-install-the-requirements","title":"3. Install the requirements","text":"<pre><code>pip install -r cet_pick/requirements.txt\n</code></pre>"},{"location":"how_we_ran_milopyp/#4-install-pytorch","title":"4. Install PyTorch","text":"<pre><code>pip install torch torchvision torchaudio\n</code></pre>"},{"location":"how_we_ran_milopyp/#5-install-cet_pick-package-and-dependencies","title":"5. Install cet_pick package and dependencies","text":"<pre><code>pip install -e cet_pick\n</code></pre>"},{"location":"how_we_ran_milopyp/#download-tutorial-dataset","title":"Download tutorial dataset","text":"<pre><code>wget https://nextpyp.app/files/data/milopyp_globular_tutorial.tbz\ntar xvfz milopyp_globular_tutorial.tbz\n</code></pre> <p>This dataset contains 5 tomograms named as <code>tilt*.rec</code> Alternatively, any of the existing datasets can be used as described below:</p>"},{"location":"how_we_ran_milopyp/#usage-instructions","title":"Usage instructions","text":"<p>There are two steps in their workflow: 1. Cellular Content Exploration 2. Particle Refined Localization  </p> <p>For comparison with the PickET output, I have only used the first (Cellular Content Exploration) step.</p>"},{"location":"how_we_ran_milopyp/#1-prepare-input-file","title":"1. Prepare input file","text":"<p>You need to make a <code>.txt</code> input file. Since we are working with only the reconstructed tomograms, we only need to make the following file: <pre><code>image_name   rec_path\n\ntomo1   path_to_rec_1\n\ntomo2   path_to_rec_2\n...\n</code></pre></p> <p>where <code>path_to_rec_1</code> is the path to a reconstructed tomogram. More than one tomogram can be processed at a time.</p> <p>Note</p> <p>This is a tab separated file.</p> <p>Note</p> <p>Although tilt-series files are available for tutorial dataset, I am assuming that we don't have access to these as for all the tomograms in our dataset, there are no tilt-series files available</p> <p>Place this file in a <code>data/</code> directory. Ensure to name the directory <code>data</code>. But whenever pointing to this file in the subsequent steps, you don't need to mention <code>data/</code>. </p> <p>Important</p> <p>Note that the scripts will automatically add this to the prefix whenever you open this file from their scripts.</p>"},{"location":"how_we_ran_milopyp/#2-train-the-model","title":"2. Train the model","text":"<p>Again, I used the <code>3d</code> mode of the workflow assuming that we don't have access to the tilt-series. The model was trained on all the tomograms in a given dataset and the predictions were also performed on the entire dataset. <pre><code>python cet_pick/cet_pick/simsiam_main.py simsiam3d --num_epochs 20 --exp_id test_sample --bbox 36 --dataset simsiam3d --arch simsiam2d_18 --lr 1e-3 --train_img_txt sample_train_explore_img.txt --batch_size 256 --val_intervals 20 --save_all --gauss 0.8 --dog 3,5 --order xyz\n</code></pre></p> <p>where <code>sample_train_explore_img.txt</code> is the tab separated file that we made above. I did not tweak with other hyperparameters. You can change the value of <code>--exp_id</code> to give a name to your dataset. </p>"},{"location":"how_we_ran_milopyp/#3-inference-step","title":"3. Inference step","text":"<p>Again, I used the <code>3d</code> mode of the workflow assuming that we don't have access to the tilt-series. <pre><code>python cet_pick/cet_pick/simsiam_test_hm_3d.py simsiam3d --exp_id test_sample --bbox 36 --dataset simsiam3d --arch simsiam2d_18 --test_img_txt sample_train_explore_img.txt --load_model exp/simsiam3d/test_sample/model_20.pth --gauss 0.8 --dog 3,5 --order xyz\n</code></pre></p> <p>where <code>sample_train_explore_img.txt</code> is the tab separated file that we made above. Note that the inference may also be performed on other tomograms using the same trained model.</p>"},{"location":"how_we_ran_milopyp/#4-2d-visualization","title":"4. 2D visualization","text":"<p>This step also perform UMAP and clustering. This step is needed to get the coordinates of predicted particles. <pre><code>python cet_pick/cet_pick/plot_2d.py --input exp/simsiam2d3d/test_sample/all_output_info.npz --n_cluster 48 --num_neighbor 40 --mode umap --path exp/simsiam2d3d/test_sample/ --min_dist_vis 1.3e-3 --gpus '-1'\n</code></pre></p> <p>Note</p> <p>All the output files are stored in a directory called <code>exp</code>. This directory will be automatically generated.</p>"},{"location":"how_we_ran_milopyp/#5a-convert-the-predicted-coordinates-to-a-yaml-file-similar-to-one-that-picket-workflow-generates","title":"5A. Convert the predicted coordinates to a yaml file similar to one that PickET workflow generates","text":"<p>This is a custom script that I wrote to evaluate coordinates predicted by MiLoPYP using our evaluation scripts. <pre><code>python pickET/accessories/convert_milopyp_preds_to_yaml.py ../milopyp/tomotwin_8tomo_r1/exp/simsiam3d/tomotwin_8r1/all_output_info.npz ../milopyp/tomotwin_8tomo_r1/data/tomotwin_input.txt  /data2/shreyas/mining_tomograms/working/s1_clean_results_picket_v2/tomotwin_8tomos_r1_milopyp_preds/\n</code></pre></p> <p>This script takes the output from MiLoPYP as input along with the input .txt file used to run MiLoPYP and the output directory where the newly generated file should be saved. The output is a yaml file in a form similar to the output from PickET. It can then be visualized with the <code>see_centroids.py</code> from PickET accessories.</p> <p>Note</p> <p>This is where I stopped when I was comparing the MiLoPYP and PickET predictions.</p>"},{"location":"how_we_ran_milopyp/#6a-setting-up-the-environment-for-the-interactive-steps","title":"6A. Setting up the environment for the interactive steps","text":"<p>MiLoPYP uses Arize-AI's Phoenix library for interactive visualization in 3D. Note that the Phoenix library installed in the MiLoPYP conda environment will likely now work due to some broken Numpy dependencies. I had created a separate <code>venv</code> environment for <code>Phoenix</code> outside the MiLoPYP conda environment using the following steps: <pre><code>conda deactivate\ncd ~/Projects/mining_tomograms/environments\nmkdir phoenix\npython -m venv phoenix\nsource ~/Projects/mining_tomograms/environments/phoenix/bin/activate\npip install arize-phoenix\npip install arize-phoenix[embeddings]\n</code></pre></p> <p>Note</p> <p>Make sure to deactivate the MiLoPYP conda environment and activate the phoenix venv environment before running the interactive steps.</p>"},{"location":"how_we_ran_milopyp/#7-3d-interactive-session","title":"7. 3D interactive session","text":""},{"location":"how_we_ran_milopyp/#1-load-local-images","title":"1. Load local images","text":"<p>Loading local images generated by <code>plot_2d.py</code> in the directory <code>exp/simsiam3d/test_sample/imgs/</code> onto a server by running the following command: <pre><code>python -m http.server 7000\n</code></pre></p>"},{"location":"how_we_ran_milopyp/#2-start-the-interactive-session","title":"2. Start the interactive session","text":"<p>Deactivate the MiLoPYP conda environment and activate the <code>phoenix</code> venv environment made in step 6A by running the following command: <pre><code>conda deactivate\nsource ~/Projects/mining_tomograms/environments/phoenix/bin/activate\n</code></pre></p> <p>Important</p> <p>Modify the <code>cet_pick/cet_pick/phoenix_visualization.py</code> as follows:</p> <p>First, import time module by adding the following line at the top of the script: <pre><code>import time\n</code></pre></p> <p>Then, change line 78 in  from: <pre><code>    session = px.launch_app(train_ds)\n</code></pre> to <pre><code>    print(\"Launching app\")\n    session = px.launch_app(train_ds)\n\n    print(f\"Phoenix UI launched at: {session.url}\")\n    print(\"Press Ctrl+C to stop the server and exit.\")\n\n    # Keep the script running indefinitely\n    try:\n        while True:\n            time.sleep(1)  # Sleep for a short duration to prevent busy-waiting\n    except KeyboardInterrupt:\n        print(\"\\nPhoenix server stopped by user (Ctrl+C detected).\")\n</code></pre></p> <p>Now, in a new terminal tab, activate the <code>phoenix</code> venv environment and start the Phoenix server by running the following command: <pre><code>source ~/Projects/mining_tomograms/environments/phoenix/bin/activate\nphoenix serve\n</code></pre></p> <p>Then, go back to the previous terminal tab and run the following python script to start the interactive session: <pre><code>python cet_pick/cet_pick/phoenix_visualization.py --input exp/simsiam3d/test_sample/interactive_info_parquet.gzip\n</code></pre></p> <p>In the terminal output, look for the following text:  <pre><code>To view the Phoenix app in you browser, visit http://localhost:xxxx\n</code></pre></p> <p>Where, <code>xxxx</code> corresponds to the port on which Phoenix app is hosted. Open the link in a browser window. Follow the instructions on the MiLoPYP tutorial to select embeddings. You can then download the coordinates of the particles corresponding to the selected embeddings in .parquet format.</p>"},{"location":"input_for_s1/","title":"Step 1 (S1): Generate semantic segmentations","text":""},{"location":"input_for_s1/#inputs-for-s1","title":"Inputs for S1","text":"<p>Inputs for S1 are provided through a YAML file containing parameters. An example is provided in <code>examples/s1_params_example.yaml</code>. </p>"},{"location":"input_for_s1/#dataset-related","title":"Dataset related","text":"<p>These parameters are described in detail below: <pre><code>dataset_name: &lt;An identifier for the dataset&gt; \n</code></pre></p> <p><code>dataset_name</code> is also the name of the directory where all the outputs will be saved.</p> <pre><code>inputs: \n[  \n    {\n    tomogram: &lt;path_to_tomogram_1&gt;,\n    lower_z-slice_limit: &lt;upper_zslice_where_the_lamella_starts&gt;, #[Optional]#\n    upper_z-slice_limit: &lt;lower_zslice_where_the_lamella_ends&gt; #[Optional]#\n        },\n    {\n    tomogram: &lt;path_to_tomogram_2&gt;,\n    lower_z-slice_limit: &lt;upper_zslice_where_the_lamella_starts&gt;, #[Optional]#\n    upper_z-slice_limit: &lt;lower_zslice_where_the_lamella_ends&gt; #[Optional]#\n        },\n]\n</code></pre> <p><code>inputs</code> is a list (enclosed within square brackets) that can be expanded with similar entries, enclosed in curly brackets as shown above. </p> <p></p> <p>Fig. 1: Central Z-slice from an example input tomogram. Tomogram obtained from CZI-10301 (Khavnekar, S. et al. Microscopy and Microanalysis (2023)) </p> <p><code>lower_z-slice_limit</code> and <code>upper_z-slice_limit</code> denote the upper and lower bounds on the Z-slices where the <code>tomogram</code> is of the highest quality and is most likely to contain good particles. An example input tomogram denoised with TomoEED is shown in Fig 1.  </p> <p>Note</p> <p>These bounds are only considered for fitting the clustering algorithm that separates particle voxels from background voxels. Particle localizations may still be predicted on Z-slices beyond the mentioned bounds. Using these bounds in S1 may help avoid the contaminants from the periphery of the lamella from confounding the clustering algorithm. (See also: Fig 2).  Moreover, these allow help process larger tomograms without increasing the processing speed and GPU memory requirement. </p> <p>The entries marked as <code>#[Optional]#</code> may be omitted. If you do not wish to specify these, these lines should be deleted from from the <code>param_file.yaml</code>.</p> <p></p> <p>Fig. 2: Z-slice bounds for the two steps in PickET.  The figure shows a slice of a tomogram along the Z-axis along with  annotations for the upper and lower bounds to be specified for a PickET run </p>"},{"location":"input_for_s1/#picket-core-parameters","title":"PickET core parameters","text":"<pre><code>neighborhood_size: 5\n</code></pre> <p>We recommend using the <code>neighborhood_size: 5</code> for picking particles from tomograms. This corresponds to a neighborhood of \\(5 \\times 5 \\times 5\\) voxels around a given voxel. </p> <pre><code>max_num_neighborhoods_for_fitting: 100_000_000 \n</code></pre> <p>This parameter specifies the number of voxels to be used for fitting the clustering algorithm. Reducing this number will reduce the computational memory/time, but will come at the cost of accuracy. On the contrary, increasing this number will increase the time/memory but may result in better segmentations.</p> <p>We recommend users to optimize this number according to the computing time and GPU memory available. This number needs to be optimized only once for a computing node. Once optimized, the same can be used for all datasets that will be processed using PickET on that computing node in the future.</p> <p>Note</p> <p>The number of neighborhoods being used in a run is shown in the terminal output for the run. It will be shown as <code>Features array of shape: (&lt;num_neighborhoods_being_used&gt;, &lt;num_features_extracted&gt;)</code> in the terminal output. </p>"},{"location":"input_for_s1/#feature-extraction-parameters","title":"Feature extraction parameters","text":"<pre><code>feature_extraction_params: \n[\n    {\n    mode: ffts, \n    n_fft_subsets: 64,\n        },\n\n    {\n    mode: gabor, \n    num_sinusoids: 10, \n    num_neighborhoods_subsets: 5,\n    num_parallel_filters: 8,\n    num_output_features: 64\n        },\n\n    {\n    mode: intensities\n        }  \n]\n</code></pre> <p>These parameters describe the feature extraction modes. Similar to <code>inputs</code>, <code>feature_extraction_params</code> is also a list of dictionaries. Each dictionary defined in this list describes a feature extraction mode. Here, we provide three feature extraction modes <code>ffts</code>, <code>gabor</code> and <code>intensities</code>. </p> <p>First, for <code>mode: ffts</code>, there is only one parameter, <code>n_fft_subsets</code>. This parameter defines how many neighborhoods will be processed simultaneously for feature extraction. Higher the value, the faster the FFT feature extraction, but higher the computational memory required.</p> <p>Second, for <code>mode: gabor</code>, there are four key parameters. The number of Gabor filters used for Gabor feature extraction is the cube of the <code>num_sinusoids</code>. The user may choose to not tweak this parameter. The <code>num_neighborhoods_subsets</code> and <code>num_parallel_filters</code> define the number of neighborhoods and number of Gabor filters to be processed simultaneously. Increasing the <code>num_neighborhoods_subsets</code> and reducing the <code>num_parallel_filters</code> will result in the feature extraction requiring less GPU memory, but will result in longer runtimes. The <code>num_output_features</code> defines the number of features with the highest standard deviation to be used for clustering. The user may choose not to tweak this parameter.</p> <p>Third, for <code>mode: intensities</code>, there are no parameters. It will use the voxel intensities obtained from the neighborhoods as features for clustering.</p>"},{"location":"input_for_s1/#clustering-methods","title":"Clustering methods","text":"<pre><code>clustering_methods: [kmeans, gmm]\n</code></pre> <p><code>clustering_methods</code> is a list that describes the clustering algorithms to be used. In this example, both <code>KMeans</code> as well as <code>GMM</code> will be used for clustering.</p>"},{"location":"input_for_s1/#output-directory","title":"Output directory","text":"<pre><code>output_dir: /data/picket_results/\n</code></pre> <p>As the name suggests, <code>output_dir</code> describes the path to the directory where the output segmentations will be saved.  </p> <p>Note</p> <p>The segmentations will be saved in <code>output_dir/dataset_name/</code> directory.</p> <p></p> <p>Back to Home Go to usage instructions Go to running s1</p>"},{"location":"input_for_s2/","title":"Step 2 (S2): Localize particles","text":""},{"location":"input_for_s2/#inputs-for-s2","title":"Inputs for S2","text":"<p>Inputs for S2 are provided through a YAML file containing parameters. An example is provided in <code>examples/s2_params_example.yaml</code>. These parameters are described in detail below:</p> <pre><code>dataset_name: &lt;An identifier for the dataset&gt;\n</code></pre> <p><code>dataset_name</code> is also the name of the directory where all the outputs will be saved. <pre><code>inputs: \n[  \n    {\n        segmentation: &lt;path_to_segmentation_1&gt;, \n        particle_cluster_id: 1,  # Cluster index of the particle cluster \n        lower_z-slice_limit: &lt;upper_zslice_where_the_lamella_starts&gt;, #[Optional]#\n        upper_z-slice_limit: &lt;lower_zslice_where_the_lamella_ends&gt; #[Optional]#\n        },\n    {\n        segmentation: &lt;path_to_segmentation_1&gt;, \n        particle_cluster_id: 0,\n        lower_z-slice_limit: &lt;upper_zslice_where_the_lamella_starts&gt;, #[Optional]#\n        upper_z-slice_limit: &lt;lower_zslice_where_the_lamella_ends&gt; #[Optional]#\n        },\n]\n</code></pre></p> <p><code>inputs</code> is a list (enclosed within square brackets) that can be expanded with similar entries, enclosed in curly brackets as shown above. </p> <p><code>segmentation</code> and the corresponding <code>particle_cluster_id</code> are obtained from the visualizing segmentations.  <code>lower_z-slice_limit</code> and <code>upper_z-slice_limit</code> denote the upper and lower bounds on the Z-slices where the tomogram is likely to contain particles. </p> <p>Note</p> <p>These bounds define the bounds on the region from which particles will be picked. These bounds can be more relaxed than the ones used for generating semantic segmentations. See also Fig 2. </p> <p></p> <p>Fig. 2: Z-slice bounds for the two steps in PickET </p> <pre><code>particle_extraction_params: \n[\n    {mode: connected_component_labeling},\n    {mode: watershed_segmentation, min_distance: 15}\n]\n</code></pre> <p>Similar to the <code>inputs</code>, <code>particle_extraction_params</code> is also a list of dictionaries. Each dictionary defined in this list defines a particle extraction mode. Here, we provide two particle extraction modes <code>connected_component_labeling</code> and <code>watershed_segmentation</code>. </p> <p>First, for <code>mode: connected_component_labeling</code>, there are no hyperparameters. This mode is fast and works well for less crowded datasets.</p> <p>Second, for <code>mode: watershed_segmentation</code>, there is one hyperparameter. This mode uses watershed segmentation for converting the semantic segmentation into instance segmentation. It uses the <code>min_distance</code> hyperparameter that defines the minimum separation between two detected particles in voxels.</p> <pre><code>output_dir: /data/picket_results/\n</code></pre> <p>As the name suggests, <code>output_dir</code> describes the path to the directory where the output segmentations will be saved.  </p> <p>Note</p> <p>The extracted particle centroid coordinates will be saved as <code>.yaml</code> files in <code>output_dir/dataset_name/predicted_particles/</code> directory.</p> <p></p> <p></p> <p>Back to Home Go to usage instructions Go to running s2</p>"},{"location":"installation/","title":"Getting started","text":"<p>This document provides a detailed guide for installing PickET.</p>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<ul> <li>Python dependencies can be found in <code>pyproject.toml</code>.</li> <li>TomoEED</li> </ul> <p>Instructions for installing the Python dependencies, CuPy and TomoEED are provided below:</p>"},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#1-create-a-new-virtual-environment","title":"1. Create a new virtual environment","text":"<p>In a new terminal window, run the following command to install venv package: <pre><code>pip install venv\n</code></pre></p> <p>Note</p> <p>On Ubuntu-like operating systems, this command needs to be run as shown here: <pre><code>sudo apt install python3-venv \n</code></pre></p> <p>Then, run the following commands sequentially to create a new virtual environment: <pre><code>mkdir &lt;path_to_new_virtual_environment&gt;\ncd &lt;path_to_new_virtual_environment&gt;\npython -m venv picket_env\n</code></pre></p>"},{"location":"installation/#2-activate-the-environment","title":"2. Activate the environment","text":"<pre><code>source &lt;path_to_new_virtual_environment&gt;/bin/activate\n</code></pre> <p>Note</p> <p>Make sure to activate the environment before installing rest of the dependencies and before running PickET. The virtual environment can be deactivated by running <code>deactivate</code> in the terminal or simply by closing the terminal window.</p>"},{"location":"installation/#3-install-cupy","title":"3. Install CuPy","text":"<p>If the CUDA version is <code>12.&lt;something&gt;</code>, install CuPy by running</p> <pre><code>pip install cupy-cuda12x\n</code></pre> <p>Else if CUDA version is <code>11.&lt;something&gt;</code>, install CuPy by running.</p> <pre><code>pip install cupy-cuda11x\n</code></pre> <p>Note</p> <p>The CUDA version can be checked by running <code>nvidia-smi</code> from the terminal. It will be shown on the top right corner in the generated output.</p>"},{"location":"installation/#4-install-all-the-picket","title":"4. Install all the PickET","text":"<p><pre><code>git clone https://github.com/isblab/pickET.git\ncd pickET\npip install .\n</code></pre> Installing PickET via <code>pip</code> using the above command builds executables for the two steps in a PickET run - generating semantic segmentation and localizing particles. (See also Usage instructions)</p>"},{"location":"installation/#5-install-tomoeed","title":"5. Install TomoEED","text":"<ol> <li> <p>Visit the official TomoEED webpage.  </p> </li> <li> <p>Fill and submit the Google Form.  </p> </li> <li> <p>Copy the generated download link and paste it in a new browser tab. This will download TomoEED as a zipped directory. Unzip it.   </p> </li> </ol> <p>Back to Home Go to usage instructions </p>"},{"location":"obtaining_particle_cluster_id/","title":"Obtaining particle cluster ID","text":"<p>Look at the each of the six segmentations generated from S1 for the tomograms in the dataset following the instructions in visualizing segmentations. Identify the segmentation(s) in which particles are well separated from the background. More than one segmentation may be chosen for the next step. </p> <p>For each of the chosen segmentations, identify the voxel value for the voxel corresponding to particles in the segmentation. This value is different for each segmentation. It could be 0 or 1 and is called the <code>particle_cluster_id</code>. Either of the following ways can be used to obtain the <code>particle_cluster_id</code>:</p> <ol> <li> <p>Check if a target particle is colored with a non-gray color in this overlay. If the particle is colored, then <code>particle_cluster_id = 1</code>, else <code>particle_cluster_id = 0</code>. (See also Fig. 3A. In this figure, it is visually apparent that the particles are segmented in a non-gray color, orange in this case. Therefore, for this example, <code>particle_cluster_id = 1</code>.)</p> </li> <li> <p>Hover over a target particle in the loaded Napari window (as shown in Fig. 3B). The <code>particle_cluster_id</code> should appear at the bottom of the window next to the coordinates of the mouse pointer (as shown in Fig. 3C).</p> </li> </ol> <p>Important</p> <p>The <code>particle_cluster_id</code> may not be the same for all the segmentations generated from S1 for a given tomogram.</p> <p></p> <p>Fig. 3: Obtaining the \"particle_cluster_id\""},{"location":"outputs/","title":"Understanding outputs from PickET","text":"<p>A standard run of the PickET library results in the following outputs:  </p> <ol> <li>Semantic segmentations from S1  </li> <li>Instance segmentations from S2  </li> <li>Predicted particle centroids from S2  </li> </ol> <p>These are described in more details below:</p>"},{"location":"outputs/#output-from-s1","title":"Output from S1","text":"<p>The output from S1 is a number of semantic segmentations. These can be visualized using the instructions in visualizing segmentations (e.g. Fig 2A). </p> <p>Note</p> <p>For each input tomogram six output semantic segmentations will be generated - each using one of the PickET S1 workflows (for example intensities_kmeans, intensities_gmm, gabor_kmeans, etc.). The users may choose to use more than one of these semantic segmentations in the next step, S2.</p> <p></p> <p>Fig. 2A: Output from S1 - Semantic segmentation </p> <p>Before proceeding to the next step, one needs to identify the <code>particle_cluster_id</code> corresponding to each of the semantic segmentation step that will be passed to S2. Refer to obtaining particle cluster ID for further instructions on this.</p>"},{"location":"outputs/#output-from-s2","title":"Output from S2","text":"<p>The principal output from S2 is a number of <code>.yaml</code> files containing the predicted particle coordinates along with its associated metadata. These files are text files that can be opened in any text editor. One can also visualize the predicted centroids overlayed on the input tomogram using see centroids script (Fig. 4). This script can be run as follows: <pre><code>python src/picket/accessories/see_centroids.py &lt;path_to_predicted_centroids&gt;\n</code></pre></p> <p>Note</p> <p>For each input tomogram several output particle centroid prediction files will be generated - each using one of the PickET S1 and S2 workflows (for example intensities_kmeans_CC, intensities_kmeans_WS, gabor_kmeans_CC, gabor_kmeans_WS, etc.). In general, the number of output prediction files will be two times the number of input semantic segmentations.</p> <p></p> <p>Fig. 4: Output from S2 - Predicted centroids</p> <p>In addition, instance segmentations will also be generated associated with each of the predicted centroids file. These can also be visualized following the instructions provided in visualizing segmentations (Fig. 2B).</p> <p></p> <p>Fig. 2B: Output from S2 - Instance segmentation</p> <p>Note</p> <p>An optimal instance segmentation is one in which, first, the particles are well separated from the background and, second, the individual particle instances are well separated from each other.</p> <p>The predicted particle coordinates are based on Cartesian coordinate system that assumes the top-left-front of the tomogram to be the origin (0,0,0). These predicted coordinates can be converted to assume any other point in the tomogram as the origin and the origin adjusted predictions can be exported in <code>.csv</code> format using the converter script which can be run as follows: <pre><code>python src/picket/accessories/offset_correct_pred_centroids_and_convert_to_csv.py -i &lt;input_fname&gt; -o &lt;output_dir&gt; -n \"&lt;new_origin&gt;\"\n</code></pre></p> <p>where <code>&lt;new_origin&gt;</code> must be specified as <code>\"(z,y,x)\"</code> where z, y, and x are coordinates of the new origin with respect to the current origin (top-left-front) of the tomogram specified as integers.  </p> <p>Important</p> <p><code>&lt;new_origin&gt;</code> must be specified within quotes.</p> <p>Subtomograms corresponding to the particle centroids may also be extracted as <code>.npy</code> files using the subtomogram extraction script as follows: <pre><code>python src/picket/accessories/extract_subtomograms.py &lt;coords_fpath&gt; &lt;subtomogram_size&gt; &lt;output_dir&gt;\n</code></pre> where <code>coords_fpath</code> corresponds to the path to a <code>.yaml</code> predicted coordinates file; <code>subtomogram_size</code> corresponds to the size of the subtomograms specified in number of voxels; and <code>output_dir</code> is the path to the directory where the extracted subtomograms should be saved.</p>"},{"location":"preproc_gt/","title":"Preprocessing the ground truth annotations","text":""},{"location":"preproc_gt/#offset-correction-and-concatenating-the-annotation-files","title":"Offset correction and concatenating the annotation files","text":"<p>We use ground truth files in <code>.ndjson</code> format with the particle centroid coordinates mentioned with respect to the origin situated at the top left front corner of the tomogram. </p>"},{"location":"preproc_gt/#for-tomotwin-dataset","title":"For TomoTwin dataset","text":"<p>We noticed that the ground truth annotations had an offset. This was corrected by running the tomotwin ground truth preprocessing script which can be run as follows: <pre><code>python accessories/preprocess_ground_truth/generate_ndjson_ground_truth_tomotwin.py &lt;parent_dir&gt; &lt;x&gt; &lt;y&gt; &lt;z&gt;\n</code></pre></p> <p>where, <code>parent_dir</code> is the directory of a round of simulated tomograms, and <code>x</code>, <code>y</code> and <code>z</code> denote the size of the tomogram along the three axes.</p>"},{"location":"preproc_gt/#for-czi-datasets","title":"For CZI datasets","text":"<p>We noticed that the ground truth annotations did not have any offset. The coordinate files were concatenated to a single file by czi ground truth preprocessing script which can be run as follows: <pre><code>python accessories/preprocess_ground_truth/generate_ndjson_ground_truth_czi.py &lt;parent_dir&gt; \n</code></pre></p> <p>where <code>&lt;parent_dir&gt;</code> corresponds to the <code>annotations</code> directory associated with each tomogram.</p>"},{"location":"running_s1/","title":"Step 1 (S1): Generate semantic segmentations","text":""},{"location":"running_s1/#running-s1","title":"Running S1","text":""},{"location":"running_s1/#1-denoise-tomograms","title":"1. Denoise tomograms","text":"<p>First, denoise the input tomograms using <code>TomoEED</code> by running the following command: <pre><code>&lt;tomoeed_directory&gt;/bin/tomoeed full_path_to_input_tomogram.mrc denoised_tomograms/output_tomogram.mrc\n</code></pre> This will make a denoised version of the input tomogram (<code>input_tomogram.mrc</code>) and place it at <code>denoised_tomograms/output_tomogram.mrc</code>. If running from a different directory than <code>input_tomogram.mrc</code>, you will need to specify the full path to the input tomogram.</p> <p>Important</p> <p>Make sure to use the path to denoised tomogram (<code>denoised_tomograms/output_tomogram.mrc</code>) in the <code>s1_param_file_path</code> for <code>tomogram</code> in the <code>inputs</code> section. </p>"},{"location":"running_s1/#2-generate-semantic-segmentations","title":"2. Generate semantic segmentations","text":"<p>Run the following command to generate the semantic segmentations. <pre><code>python src/picket/s1.py &lt;s1_param_file_path&gt;\n</code></pre> Next step is to choose one or more optimal segmentations for each input tomogram and obtaining the corresponding particle cluster IDs. Follow the instructions at visualizing segmentations and obtaining particle cluster ID for more details on this.</p> <p></p> <p>Back to Home Go to outputs Go to usage instructions </p>"},{"location":"running_s2/","title":"Step 2 (S2): Localize particles","text":""},{"location":"running_s2/#running-s2","title":"Running S2","text":"<p>Run the following command to obtain centroids for predicted particles.</p> <pre><code>python src/picket/s2.py &lt;s2_param_file_path&gt; \n</code></pre> <p></p> <p>Back to Home Go to outputs Go to usage instructions </p>"},{"location":"usage_instructions/","title":"Usage instructions","text":"<p>PickET is a modular library that provides a variety of workflows for particle-picking in cryo-electron tomograms. </p> <p>A typical PickET run comprises two steps - S1 and S2, described in more detail below. </p> <p>Note</p> <p>We strongly recommend running all the steps described below on a single computing node (a local workstation or a remote computing cluster). Several intermediate files are generated at different stages in the pipeline. These files contain pointers to the input data which is required for downstream processes. These pointers may not work if the data is transferred to a different computing system.</p> <p>Warning</p> <p>Make sure to activate the environment before running PickET. See create and activate virtual environment for more details.</p>"},{"location":"usage_instructions/#s1-generate-semantic-segmentation","title":"S1 - Generate semantic segmentation","text":"<p>The first step (S1, semantic segmentation) identifies voxels corresponding to particles in each input tomogram. This step involves three feature extraction modes (<code>FFTs</code>, <code>Gabor</code>, and <code>intensities</code>) and two clustering algorithms (<code>KMeans</code> and <code>GMM</code>) to classify each voxel as a particle or background. In total, this generates six semantic segmentations for each input tomogram, corresponding to every combination of feature extraction mode and clustering algorithm. The users may then proceed with one or more of these six segmentations for the second step. </p> <p>Note</p> <p>That a workflow that generates the most optimal segmentation for a given tomogram may not necessarily generate the most optimal segmentations for all tomograms in that dataset. </p> <p>The output segmentations generated from S1 can be visualized by following the instructions in visualizing the output segmentations. From all the segmentations generated from S1 for a given tomogram, identify the segmentation(s) in which particles are well separated from the background. More than one segmentation may be chosen for the next step. Follow the instructions in obtaining particle cluster ID to get the voxel value for the voxel corresponding to particles in the segmentation. This value is specific for each segmentation and is passed as an input (<code>particle_cluster_id</code>) for S2.</p> <p>Inputs for S1\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0How to run S1?\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0Outputs Visualizing the output segmentations\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0Obtaining particle cluster ID </p>"},{"location":"usage_instructions/#s2-localize-particles","title":"S2 - Localize particles","text":"<p>In the second step (S2, particle localization), particle segmentations are obtained using two segmentation methods (<code>connected component labeling</code> and <code>watershed segmentation</code>), allowing the user to choose between the two. The centroids of predicted particles are provided as output. Users also have the option to obtain subtomograms enclosing the predicted particles for downstream subtomogram averaging. </p> <p>Inputs for S2\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0How to run S2?\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0Outputs Visualizing the output segmentations</p> <p>Note</p> <p>PickET is best run on a large computing node (a local workstation or a remote computing cluster, if you have access to high-performance computing). Otherwise, the following options can be adjusted to run it on the available memory.    1. The central Z-slab can be made narrower for fitting the clusterer by setting a <code>lower_z-slice_limit</code> and <code>upper_z-slice_limit</code>.    2. The <code>max_num_neighborhoods_for_fitting</code> can be decreased. Note that these changes need to be made only for the S1 stage (feature extraction and clustering) and not S2 stage.</p> <p></p> <p>Back to Home Go to installation instructions</p>"},{"location":"visualizing_segmentations/","title":"Visualizing segmentations","text":"<p>Now, run the following command on each of the segmentations to visualize an overlay of the segmentation on the input tomogram in Napari: <pre><code>python src/picket/accessories/see_segmentations.py &lt;path_to_segmentation&gt; &lt;segmentation_type&gt;\n</code></pre></p> <p>where <code>segmentation_type</code> is either <code>semantic_segmentation</code> or <code>instance_segmentation</code>.</p> <p>Note</p> <p>This step displays the segmentation overlayed on the input tomogram in a Napari window. </p> <p></p> <p>Fig. 2A: Output from S1 - Semantic segmentation</p> <p></p> <p>Fig. 2B: Output from S2 - Instance segmentation</p> <p></p> <p>Back to Home Go to usage instructions Go to obtaining particle cluster ID </p>"}]}